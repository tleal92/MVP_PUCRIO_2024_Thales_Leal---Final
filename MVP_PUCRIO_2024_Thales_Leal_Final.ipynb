{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Projeto de Machine Learning - Banco de Dados do Banco**\n",
        "\n",
        "Este projeto consiste em aplicar técnicas de Machine Learning em um dataset sobre clientes de um banco, com o objetivo de prever se o cliente vai assinar um depósito a prazo. O código é dividido em etapas para seguir o fluxo recomendado: carregamento, preparação, modelagem, avaliação e otimização."
      ],
      "metadata": {
        "id": "Mgpm6G1i2S0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Baixar e Extrair o Dataset**\n",
        "\n",
        "Primeiro, vamos fazer o download e a extração do dataset."
      ],
      "metadata": {
        "id": "8ZzrWjEC2nPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "\n",
        "# URL do dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip\"\n",
        "zip_file_path = \"bank.zip\"\n",
        "extract_folder = \"bank_dataset\"\n",
        "\n",
        "# Baixando e extraindo o dataset\n",
        "print(\"Baixando dataset...\")\n",
        "response = requests.get(url)\n",
        "with open(zip_file_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(\"Extraindo arquivos...\")\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "# Definindo caminho do arquivo CSV\n",
        "csv_file = os.path.join(extract_folder, \"bank-full.csv\")\n",
        "\n",
        "# Carregando o dataset\n",
        "print(\"Carregando o dataset...\")\n",
        "df = pd.read_csv(csv_file, sep=\";\")\n",
        "\n",
        "# Exibindo as primeiras linhas do dataset\n",
        "print(\"Dataset carregado com sucesso!\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNhMR9pl20To",
        "outputId": "9e36c175-386e-4f32-95d9-4e1fe9701378"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baixando dataset...\n",
            "Extraindo arquivos...\n",
            "Carregando o dataset...\n",
            "Dataset carregado com sucesso!\n",
            "   age           job  marital  education default  balance housing loan  \\\n",
            "0   58    management  married   tertiary      no     2143     yes   no   \n",
            "1   44    technician   single  secondary      no       29     yes   no   \n",
            "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
            "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
            "4   33       unknown   single    unknown      no        1      no   no   \n",
            "\n",
            "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
            "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
            "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
            "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
            "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
            "4  unknown    5   may       198         1     -1         0  unknown  no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Preparação e Pré-processamento dos Dados**\n",
        "\n",
        "Aqui, vamos tratar valores ausentes, codificar variáveis categóricas e separar as variáveis independentes da variável alvo."
      ],
      "metadata": {
        "id": "f3OuJhy45FPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Excluindo colunas desnecessárias\n",
        "df.drop(columns=['duration'], inplace=True)  # 'duration' não é relevante para o modelo\n",
        "\n",
        "# Codificando variáveis categóricas\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "label_encoders = {}\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Separando variáveis independentes e dependentes\n",
        "X = df.drop('y', axis=1)\n",
        "y = df['y']\n",
        "\n",
        "# Dividindo os dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "562YUA0C5Z8S"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Construção do Pipeline**\n",
        "\n",
        "Vamos criar um pipeline para realizar a transformação dos dados e o treinamento do modelo de forma eficiente e modular."
      ],
      "metadata": {
        "id": "pVz8D1YR5voH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando o pipeline\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Substituindo valores ausentes pela moda\n",
        "    ('scaler', StandardScaler())  # Normalizando as variáveis para melhorar o desempenho do modelo\n",
        "])"
      ],
      "metadata": {
        "id": "959diUkJ6Ir_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Treinamento e Avaliação dos Modelos**\n",
        "\n",
        "Aqui, treinamos três modelos diferentes: Random Forest, Logistic Regression, e SVM, e comparamos seus desempenhos."
      ],
      "metadata": {
        "id": "yGh4V3QT6NIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelos a serem testados\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'SVM': SVC(random_state=42)\n",
        "}\n",
        "\n",
        "# Treinamento, avaliação e comparação dos modelos\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nTreinando e avaliando o modelo: {model_name}\")\n",
        "\n",
        "    # Pipeline completo com o modelo\n",
        "    model_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', pipeline),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(model_pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
        "    print(f\"Cross-validation scores: {cv_scores}\")\n",
        "    print(f\"Average accuracy: {np.mean(cv_scores):.4f}\")\n",
        "\n",
        "    # Treinando no conjunto de treinamento\n",
        "    model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Avaliação no conjunto de teste\n",
        "    y_pred = model_pipeline.predict(X_test)\n",
        "    print(\"\\nMétricas de avaliação:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqRslg7a6XU-",
        "outputId": "5d9f9f1d-952c-4f55-d05a-33490d83c51f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Treinando e avaliando o modelo: Random Forest\n",
            "Cross-validation scores: [0.89225908 0.89368088 0.89145205 0.88987202 0.89066203]\n",
            "Average accuracy: 0.8916\n",
            "\n",
            "Métricas de avaliação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.98      0.94     11966\n",
            "           1       0.63      0.21      0.31      1598\n",
            "\n",
            "    accuracy                           0.89     13564\n",
            "   macro avg       0.77      0.60      0.63     13564\n",
            "weighted avg       0.87      0.89      0.87     13564\n",
            "\n",
            "[[11769   197]\n",
            " [ 1265   333]]\n",
            "\n",
            "Treinando e avaliando o modelo: Logistic Regression\n",
            "Cross-validation scores: [0.88309637 0.88293839 0.8832359  0.88212988 0.88276189]\n",
            "Average accuracy: 0.8828\n",
            "\n",
            "Métricas de avaliação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94     11966\n",
            "           1       0.45      0.01      0.02      1598\n",
            "\n",
            "    accuracy                           0.88     13564\n",
            "   macro avg       0.67      0.50      0.48     13564\n",
            "weighted avg       0.83      0.88      0.83     13564\n",
            "\n",
            "[[11948    18]\n",
            " [ 1583    15]]\n",
            "\n",
            "Treinando e avaliando o modelo: SVM\n",
            "Cross-validation scores: [0.89399684 0.89605055 0.89224206 0.89066203 0.89113604]\n",
            "Average accuracy: 0.8928\n",
            "\n",
            "Métricas de avaliação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.94     11966\n",
            "           1       0.68      0.15      0.24      1598\n",
            "\n",
            "    accuracy                           0.89     13564\n",
            "   macro avg       0.79      0.57      0.59     13564\n",
            "weighted avg       0.87      0.89      0.86     13564\n",
            "\n",
            "[[11858   108]\n",
            " [ 1364   234]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Otimização de Hiperparâmetros**\n",
        "\n",
        "Agora, vamos realizar a otimização de hiperparâmetros para o modelo Random Forest usando o GridSearchCV. O objetivo é encontrar os melhores parâmetros para o modelo, melhorando a sua performance e evitando overfitting.\n",
        "\n"
      ],
      "metadata": {
        "id": "jydlJOyKFjO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do pipeline de pré-processamento\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())  # Padronização das variáveis\n",
        "])\n",
        "\n",
        "# Parâmetros para GridSearchCV\n",
        "param_grid_rf = {\n",
        "    'classifier__n_estimators': [100, 200],  # Número de árvores\n",
        "    'classifier__max_depth': [10, 20, None],  # Limitar a profundidade\n",
        "    'classifier__min_samples_split': [2, 5]  # Exigência de amostras mínimas para divisão\n",
        "}\n",
        "\n",
        "# Inicializando o modelo RandomForest\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Pipeline completo com o modelo RandomForest\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', pipeline),\n",
        "    ('classifier', rf_model)\n",
        "])\n",
        "\n",
        "# Realizando a busca de hiperparâmetros com GridSearchCV\n",
        "grid_search = GridSearchCV(model_pipeline, param_grid_rf, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Avaliação no conjunto de teste com o melhor modelo\n",
        "y_pred = grid_search.predict(X_test)\n",
        "print(\"\\nMétricas de avaliação com o melhor modelo:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI9gSj9PUH4f",
        "outputId": "3c433b0a-9137-455e-e229-1a0ec7bdfdee"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas de avaliação com o melhor modelo:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.94     11966\n",
            "           1       0.65      0.20      0.31      1598\n",
            "\n",
            "    accuracy                           0.89     13564\n",
            "   macro avg       0.78      0.59      0.63     13564\n",
            "weighted avg       0.87      0.89      0.87     13564\n",
            "\n",
            "[[11790   176]\n",
            " [ 1274   324]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Conclusão**\n",
        "\n",
        "Esse código ajuda a prever quais clientes, no conjunto de dados, irão assinar o depósito a prazo, adicionando essa previsão como uma nova coluna no dataset original. O dataset atualizado pode ser exportado para um arquivo CSV e usado para tomar decisões de negócios, como direcionar ofertas de depósitos a prazo para os clientes identificados como prováveis assinantes."
      ],
      "metadata": {
        "id": "vwO3PxzMbdkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prevendo se os clientes irão assinar ou não o depósito a prazo\n",
        "y_pred_final = grid_search.predict(X)  # Prevendo para todos os clientes, não apenas X_test\n",
        "\n",
        "# Adicionando a previsão ao dataset original\n",
        "df['assinaram_deposito'] = y_pred_final  # 1 para quem irá assinar, 0 para quem não vai\n",
        "\n",
        "# Substituindo 1 por 'sim' e 0 por 'não' na coluna 'assinaram_deposito'\n",
        "df['assinaram_deposito'] = df['assinaram_deposito'].replace({1: 'sim', 0: 'não'})\n",
        "\n",
        "# Exibindo o dataset completo com a nova coluna 'assinaram_deposito'\n",
        "print(df)\n",
        "\n",
        "# Salvar o arquivo CSV localmente no Colab\n",
        "df.to_csv(\"bank_com_assinatura.csv\", index=False)\n",
        "\n",
        "# Baixar o arquivo para o seu computador\n",
        "files.download(\"bank_com_assinatura.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "je-FE7qkbeSl",
        "outputId": "13fb5f62-16d2-43c2-aa39-9daafa5075f5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       age           job   marital  education default  balance housing loan  \\\n",
            "0       58    management   married   tertiary      no     2143     yes   no   \n",
            "1       44    technician    single  secondary      no       29     yes   no   \n",
            "2       33  entrepreneur   married  secondary      no        2     yes  yes   \n",
            "3       47   blue-collar   married    unknown      no     1506     yes   no   \n",
            "4       33       unknown    single    unknown      no        1      no   no   \n",
            "...    ...           ...       ...        ...     ...      ...     ...  ...   \n",
            "45206   51    technician   married   tertiary      no      825      no   no   \n",
            "45207   71       retired  divorced    primary      no     1729      no   no   \n",
            "45208   72       retired   married  secondary      no     5715      no   no   \n",
            "45209   57   blue-collar   married  secondary      no      668      no   no   \n",
            "45210   37  entrepreneur   married  secondary      no     2971      no   no   \n",
            "\n",
            "         contact  day month  duration  campaign  pdays  previous poutcome  \\\n",
            "0        unknown    5   may       261         1     -1         0  unknown   \n",
            "1        unknown    5   may       151         1     -1         0  unknown   \n",
            "2        unknown    5   may        76         1     -1         0  unknown   \n",
            "3        unknown    5   may        92         1     -1         0  unknown   \n",
            "4        unknown    5   may       198         1     -1         0  unknown   \n",
            "...          ...  ...   ...       ...       ...    ...       ...      ...   \n",
            "45206   cellular   17   nov       977         3     -1         0  unknown   \n",
            "45207   cellular   17   nov       456         2     -1         0  unknown   \n",
            "45208   cellular   17   nov      1127         5    184         3  success   \n",
            "45209  telephone   17   nov       508         4     -1         0  unknown   \n",
            "45210   cellular   17   nov       361         2    188        11    other   \n",
            "\n",
            "         y assinaram_deposito  \n",
            "0       no                não  \n",
            "1       no                não  \n",
            "2       no                não  \n",
            "3       no                não  \n",
            "4       no                não  \n",
            "...    ...                ...  \n",
            "45206  yes                não  \n",
            "45207  yes                sim  \n",
            "45208  yes                sim  \n",
            "45209   no                não  \n",
            "45210   no                não  \n",
            "\n",
            "[45211 rows x 18 columns]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f456cd9a-bea5-4ad6-b3cb-bfed5d13e46f\", \"bank_com_assinatura.csv\", 3929721)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "synx82uDiTxX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}